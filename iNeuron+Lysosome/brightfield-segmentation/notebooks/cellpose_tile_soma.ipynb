{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45f283f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Cellpose Batch Processing with Custom Model: Soma\n",
    "* Last edited: 09/20/2025\n",
    "\n",
    "_Brief overview_: \n",
    "- Processes brightfield tile image files named W0001F0001T0001Z001C1.tif etc.\n",
    "- Saves soma-only masks as filename_seg.npy with preview outputs (.png)\n",
    "\n",
    "*See the [Cellpose distributed documentation](https://cellpose.readthedocs.io/en/latest/distributed.html) for further details.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a095ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "QUICK START - RUN WITH YOUR EMPIRICAL PARAMETERS:\n",
    "=================================================    \n",
    "The parameters will be:\n",
    "- Logged to console during processing\n",
    "- Saved in each image's summary.txt file\n",
    "- Included in the batch processing summary\n",
    "- Shown in visualization plots\n",
    "\n",
    "PARAMETER EXPLANATION:\n",
    "=====================\n",
    "- flow_threshold: Controls how strict the flow consistency requirement is. Range: 0.0-3.0.\n",
    "  Higher values (e.g., 1.0) require flows to be more consistent to keep a cell.\n",
    "  Lower values (e.g., 0.2) are more permissive. \n",
    "  \n",
    "- cellprob_threshold: Controls which pixels are considered as potential cell pixels. Range: -6.0 to 6.0.\n",
    "  Higher values (e.g., 0.4) only keep high-confidence cell pixels.\n",
    "  Lower values (e.g., -1.0) include more uncertain pixels. \n",
    "  \n",
    "- min_size: Minimum number of pixels for a detected object to be considered a cell. Default = 15\n",
    "  Smaller values detect tiny objects, larger values filter out small debris.\n",
    "  \n",
    "*Note*: These default parameters are overrided by invoking a custom trained model. If using a custom model, you can manually specify these threshold parameters to override the custom weights.   \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe3d6df",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8e4d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.10.18 \n",
      "torch version:  \t2.8.0+cu126! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n",
      "2025-09-20 15:21:28,093 [INFO] WRITING LOG OUTPUT TO C:\\Users\\neilzhao\\.cellpose\\run.log\n",
      "2025-09-20 15:21:28,094 [INFO] \n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.10.18 \n",
      "torch version:  \t2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import os, re, logging, numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellpose import models, io, utils, plot\n",
    "from cellpose.io import imread\n",
    "\n",
    "# ── Logging ────────────────────────────────────────────────────────────────\n",
    "io.logger_setup()\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "                    force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ── Paths ──────────────────────────────────────────────────────────────────\n",
    "# Set this to the top-level repo directory (parent of the script/notebook)\n",
    "REPO_ROOT = Path.cwd().parent  # already in 'vista-fish/brightfield-segmentation'\n",
    "\n",
    "MODEL_PATH  = REPO_ROOT / \"models\" / \"cpsam_soma\"\n",
    "INPUT_DIR   = REPO_ROOT / \"data\" / \"example\" / \"raw\"\n",
    "OUTPUT_DIR  = REPO_ROOT / \"data\" / \"example\" / \"interim\" / \"soma\" # masks & plots saved beside the TIFFs\n",
    "\n",
    "# ── Cellpose configuration ────────────────────────────────────────────────\n",
    "model_kwargs = dict(\n",
    "    gpu=True,\n",
    "    pretrained_model=MODEL_PATH    # custom network + saved thresholds\n",
    ")\n",
    "eval_kwargs  = dict(\n",
    "    diameter=None,      # per-image diameter estimation\n",
    "    channels=0,         # bright-field single-channel\n",
    "    do_3D=False,        # 2-D tiles\n",
    "    normalize=True,      # important for 16-bit data\n",
    "    flow_threshold=1.5,       # ↑ accept weaker flows\n",
    "    cellprob_threshold=-0.5,  # ↓ include faint cell‐prob pixels\n",
    "    # min_size=-1                # ↓ allow small neurite segments; Set to -1 to turn off this functionality. Default is 15.\n",
    ")\n",
    "# (flow_threshold, cellprob_threshold or min_size specified)\n",
    "\n",
    "# ── Helpers ────────────────────────────────────────────────────────────────\n",
    "TileRegex = re.compile(r\"^W\\d+F\\d+T\\d+Z\\d+C0?1\\.(?:tif|tiff)$\", re.IGNORECASE) # masks from BF images only\n",
    "\n",
    "def find_image_files(root_dir: str):\n",
    "    \"\"\"Return [(full_path, stem)] for CQ-1/Bio-formats-style tile names.\"\"\"\n",
    "    hits = []\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if TileRegex.fullmatch(f):\n",
    "                hits.append((os.path.join(root, f), Path(f).stem))\n",
    "    return sorted(hits)\n",
    "\n",
    "def save_segmentation_plot(img, mask, flow, out_png):\n",
    "    \"\"\"Create and save a segmentation overview figure.\"\"\"\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # try the native Cellpose visualisation first\n",
    "    success = False\n",
    "    try:\n",
    "        # flow can be list-like or ndarray; pull HSV layer if present\n",
    "        flow_hsv = flow[0] if isinstance(flow, list) and flow and flow[0].ndim == 3 else None\n",
    "        if flow_hsv is not None:\n",
    "            plot.show_segmentation(fig, img, mask, flow_hsv)\n",
    "            success = True\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"show_segmentation failed: {e}\")\n",
    "\n",
    "    if not success:\n",
    "        # fallback – three simple panels\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Raw')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask, cmap='jet' if mask.max() else 'gray')\n",
    "        plt.title(f\"Mask (n={int(mask.max())})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(plot.mask_overlay(img, mask))\n",
    "        plt.title('Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "def process_with_cellpose(image_path: str,\n",
    "                          model: models.CellposeModel,\n",
    "                          save_dir: str,\n",
    "                          fname_base: str):\n",
    "    \"\"\"Segment one image, save *_seg.npy and a diagnostic plot.\"\"\"\n",
    "    try:\n",
    "        img = imread(image_path)\n",
    "\n",
    "        if img.ndim > 2:            # take first channel if multi-channel\n",
    "            img = img[..., 0]\n",
    "\n",
    "        img = gaussian_filter(img, sigma=1)\n",
    "\n",
    "        results = model.eval([img], **eval_kwargs)\n",
    "\n",
    "        # unpack depending on Cellpose version\n",
    "        if len(results) == 4:\n",
    "            masks, flows, styles, diams = results\n",
    "            diam = diams[0] if hasattr(diams, \"__getitem__\") else diams\n",
    "        else:\n",
    "            masks, flows, styles = results\n",
    "            diam = getattr(model, \"diam_mean\", None)\n",
    "\n",
    "        mask = masks[0]\n",
    "        flow = flows[0]\n",
    "        num  = int(mask.max())\n",
    "        logger.info(f\"{Path(image_path).name}: {num} cells\")\n",
    "\n",
    "        np.save(os.path.join(save_dir, f\"{fname_base}_seg.npy\"), {\n",
    "            \"filename\" : image_path,\n",
    "            \"masks\"    : mask.astype(np.uint16),\n",
    "            \"outlines\" : utils.masks_to_outlines(mask) if num else np.zeros_like(mask),\n",
    "            \"flows\"    : flow,\n",
    "            \"diameter\" : diam,\n",
    "        })\n",
    "\n",
    "        # save visual diagnostic\n",
    "        save_segmentation_plot(img, mask, flow,\n",
    "                               os.path.join(save_dir, f\"{fname_base}_segmentation.png\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed on {image_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a952500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 15:21:28,115 - INFO - Loading Cellpose model …\n",
      "2025-09-20 15:21:28,284 - INFO - ** TORCH CUDA version installed and working. **\n",
      "2025-09-20 15:21:28,285 - INFO - >>>> using GPU (CUDA)\n",
      "2025-09-20 15:21:30,495 - INFO - >>>> loading model z:\\Active_Users_Data\\Neil\\Analyses\\Results\\dry\\xenium\\vista-fish\\brightfield-segmentation\\models\\cpsam_soma\n",
      "2025-09-20 15:21:49,354 - INFO - Found 3 TIFF tiles.\n",
      "Segmenting:   0%|          | 0/3 [00:00<?, ?it/s]2025-09-20 15:21:49,981 - WARNING - channels deprecated in v4.0.1+. If data contain more than 3 channels, only the first 3 channels will be used\n",
      "2025-09-20 15:24:04,013 - INFO - W0001F0062T0001Z001C1.tif: 140 cells\n",
      "Segmenting:  33%|███▎      | 1/3 [02:21<04:42, 141.29s/it]2025-09-20 15:24:10,821 - WARNING - channels deprecated in v4.0.1+. If data contain more than 3 channels, only the first 3 channels will be used\n",
      "2025-09-20 15:26:28,749 - INFO - W0001F0132T0001Z001C1.tif: 297 cells\n",
      "Segmenting:  67%|██████▋   | 2/3 [04:48<02:24, 144.51s/it]2025-09-20 15:26:37,598 - WARNING - channels deprecated in v4.0.1+. If data contain more than 3 channels, only the first 3 channels will be used\n",
      "2025-09-20 15:28:43,273 - INFO - W0001F0190T0001Z001C1.tif: 577 cells\n",
      "Segmenting: 100%|██████████| 3/3 [07:06<00:00, 142.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# ── Main ───────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    logger.info(\"Loading Cellpose model …\")\n",
    "    model = models.CellposeModel(**model_kwargs)\n",
    "\n",
    "    files = find_image_files(INPUT_DIR)\n",
    "    logger.info(f\"Found {len(files)} TIFF tiles.\")\n",
    "    for fpath, stem in tqdm(files, desc=\"Segmenting\"):\n",
    "        process_with_cellpose(fpath, model, OUTPUT_DIR, stem)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c03e8",
   "metadata": {},
   "source": [
    "## Plotting PNG and Stitched Outputs\n",
    "Here, we opt to also save the `_seg.npy` as `.png` binary mask outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b62733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote z:\\Active_Users_Data\\Neil\\Analyses\\Results\\dry\\xenium\\vista-fish\\brightfield-segmentation\\data\\example\\interim\\soma\\W0001F0062T0001Z001C1_seg.png\n",
      "Wrote z:\\Active_Users_Data\\Neil\\Analyses\\Results\\dry\\xenium\\vista-fish\\brightfield-segmentation\\data\\example\\interim\\soma\\W0001F0132T0001Z001C1_seg.png\n",
      "Wrote z:\\Active_Users_Data\\Neil\\Analyses\\Results\\dry\\xenium\\vista-fish\\brightfield-segmentation\\data\\example\\interim\\soma\\W0001F0190T0001Z001C1_seg.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert *_seg.npy → 16‑bit PNG masks.\n",
    "Requires\n",
    "--------\n",
    "numpy, imageio‑v3\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# edit this to point at the folder containing your *_seg.npy files\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "mask_dir = OUTPUT_DIR\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# find all *_seg.npy\n",
    "seg_files = sorted(mask_dir.glob(\"*_seg.npy\"))\n",
    "if not seg_files:\n",
    "    sys.exit(\":exclamation: No *_seg.npy files found in mask_dir\")\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# dump each \"masks\" array as a 16‑bit PNG\n",
    "for seg_path in seg_files:\n",
    "    data = np.load(seg_path, allow_pickle=True).item()\n",
    "    mask = data[\"masks\"].astype(np.uint16, copy=False)\n",
    "    png_path = seg_path.with_suffix(\".png\")\n",
    "    imageio.imwrite(png_path, mask)\n",
    "    print(f\"Wrote {png_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d0fdb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
